{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on: https://www.tensorflow.org/hub/tutorials/tf2_image_retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow import keras\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "\n",
    "image_size = (384, 384)\n",
    "print(f\"Input size {image_size}\")\n",
    "\n",
    "batch_size = 32\n",
    "data_dir = 'training_data/'\n",
    "do_fine_tuning = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean ._* files created by get_files\n",
    "!find $data_dir  -name ._\\* -delete\n",
    "!find $data_dir  -name .DS\\* -delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(subset, image_size, batch_size, data_dir):\n",
    "    return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory=data_dir,\n",
    "        validation_split=0.20,\n",
    "        subset=subset,\n",
    "        labels='inferred',\n",
    "        label_mode='categorical',\n",
    "        color_mode='rgb',\n",
    "        # Seed needs to provided when using validation_split and shuffle = True.\n",
    "        # A fixed seed is used so that the validation set is stable across runs.\n",
    "        seed=123,\n",
    "        image_size=image_size,\n",
    "        batch_size=1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_validation_dataset(batch_size, data_dir, image_size, do_data_augmentation: bool):\n",
    "    train_ds = build_dataset('training', image_size, batch_size, data_dir)\n",
    "    class_names = tuple(train_ds.class_names)\n",
    "    train_size = train_ds.cardinality().numpy()\n",
    "    train_ds = train_ds.unbatch().batch(batch_size)\n",
    "    train_ds = train_ds.repeat()\n",
    "\n",
    "    normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.0 / 255)\n",
    "    preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
    "    if do_data_augmentation:\n",
    "        preprocessing_model = tf.keras.Sequential()\n",
    "        preprocessing_model.add(tf.keras.layers.experimental.preprocessing.RandomRotation(40))\n",
    "        preprocessing_model.add(tf.keras.layers.experimental.preprocessing.RandomTranslation(0, 0.2))\n",
    "        preprocessing_model.add(tf.keras.layers.experimental.preprocessing.RandomTranslation(0.2, 0))\n",
    "        # Like the old tf.keras.preprocessing.image.ImageDataGenerator(),\n",
    "        # image sizes are fixed when reading, and then a random zoom is applied.\n",
    "        # If all training inputs are larger than image_size, one could also use\n",
    "        # RandomCrop with a batch size of 1 and rebatch later.\n",
    "        preprocessing_model.add(tf.keras.layers.experimental.preprocessing.RandomZoom(0.2, 0.2))\n",
    "        preprocessing_model.add(tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'))\n",
    "    train_ds = train_ds.map(lambda images, labels: (preprocessing_model(images), labels))\n",
    "\n",
    "    val_ds = build_dataset('validation', image_size, batch_size, data_dir)\n",
    "    val_size = val_ds.cardinality().numpy()\n",
    "    val_ds = val_ds.unbatch().batch(batch_size)\n",
    "    val_ds = val_ds.map(lambda images, labels: (normalization_layer(images), labels))\n",
    "    return train_ds, train_size, val_ds, val_size, class_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_size, val_ds, val_size, class_names = get_train_and_validation_dataset(\n",
    "        batch_size=batch_size, data_dir=data_dir, image_size=image_size, do_data_augmentation=False\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_width = image_size[0]\n",
    "image_height = image_size[1]\n",
    "input_shape = image_size + (3,)\n",
    "\n",
    "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n",
    "   weights='imagenet', \n",
    "   input_shape=input_shape,\n",
    "   include_top=False\n",
    ")\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = tf.keras.layers.Dropout(rate=0.2)(x)\n",
    "outputs = tf.keras.layers.Dense(len(class_names), activation=tf.keras.activations.softmax, kernel_regularizer=tf.keras.regularizers.l2(0.01))(x)\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=outputs, name=\"my_interpetable_model\")\n",
    "\n",
    "model.build((None,)+image_size+(3,))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0.1),\n",
    "  metrics=[\n",
    "      'accuracy'\n",
    "      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activate_early_stopping = True\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "if activate_early_stopping:\n",
    "    keras_callbacks = [early_stopping]\n",
    "else:\n",
    "    keras_callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_size // batch_size\n",
    "validation_steps = val_size // batch_size\n",
    "hist = model.fit(\n",
    "    train_ds,\n",
    "    epochs=50, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=keras_callbacks,).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(val_ds))\n",
    "image = x[0, :, :, :]\n",
    "true_index = np.argmax(y[0])\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Expand the validation image to (1, 224, 224, 3) before predicting the label\n",
    "prediction_scores = model.predict(np.expand_dims(image, axis=0))\n",
    "predicted_index = np.argmax(prediction_scores)\n",
    "print(\"True label: \" + class_names[true_index])\n",
    "print(\"Predicted label: \" + class_names[predicted_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_path = f\"saved_model_for_interpretability\"\n",
    "model.save(saved_model_path)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "925a1abfe13952b8f4ea78dbc976246d86ea16b67a6a5fd0c8bd46dc49662ed6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
